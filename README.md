# fmml20211041
### Foundations of Modern Machine Learning
## FILES IN ORDER 
1. MODULE 1 LAB 1
2. MODULE 1 LAB 2 
3. MODULE 2 LAB 1 
4. MODULE 2 LAB 2 

## MODULE 1 LAB 1 :
### Covers basics of python and some libraries such as Numpy, Matplotlib and Nltk.

* Strings, Lists, Tuples, Sets, Dictionaries, and indexing

* Functions

* numpy library: np.array, np.arange, np.eye, np normal multiplication, np point wise multiplication, np transpose, convert even elements of matrix to zero, figure out shape of matrix

* Reading files: open(), read_csv(), perform some operations on dataframes and data visualization, upload image from google drive using imread. 

## MODULE 1 LAB 2 :
### Introduce data and features 

* Extracting features from data: generating some random data using numpy and performing data visualization 

* Features of text: Download documents from Wikipedia, clean it, ount the frequency of each character in a text and plot it in a histogram,  bigrams, visualize bigrams using heatmap, top 10 ngrams for each text

* Features from written numbers: MNIST dataset, visualize few images, sum of pixel values, visualize sum of pixel values for 0 and 1, count the number black pixels that are surrounded on four sides by non-black pixels, or "hole pixels", visualize, plot for comparision, number of boundary pixels in each image, visualize, plot for comparision

* Features from CSV file: california_housing_train.csv, scatter plot visualization of three features(columns in dataset), exercise: did the same with iris dataset.


## MODULE 2 LAB 1

### SECTION 1 : distance metrics 
* Euclidean distance
* Manhattan distance 
* Hamming distance
* Cosine similarity 
* Minkowski distance 
* Chebyshev distance 
* Jaccard distance 
* How to decide appropriate distace metric?

### SECTION 2: K-Nearest Neighbor Classifier
* What is KNN?
* What is so unique about KNN?
* implementing your own version of KNN
* sklearn implementation of KNN 
* Weighted NN 
* Understanding Decision Boundaries
* Decision Boundary
* Confusion matrix
* Classification report 
* performance metrics 

### SECTION 2.1: KNN on synthetic dataset

* KNN classifier for synthetic 2-D data 

### SECTION 2.2: KNN on real world dataset

* iris flower dataset or Disher's Iris dataset

### SECTION 3: Feature Normalization

* Imputation of missing values 
* Why is feature normalization required?
* Min-Max scaling 
* Z-score clipping 
* Log normalization
* clipping  

## MODULE 2 LAB 2 
### Retrieval, Performance Evaluation and Metrics 

* Model Selection 
* Splitting of Dataset 
* Experiment with splits 
* Multiple splits (cross validation) 
* KNN using different train-test split
